#==============================================================================
#Pipeline: Academic Data Extraction & Text Metrics
#Case Study: AI & Chatbots in Educational Contexts (arXiv)
#Author: Robin Masson
#==============================================================================

import requests
from bs4 import BeautifulSoup
import pandas as pd
import json

def scrape_educational_research():
    """
    Automated extraction of recent academic publications to analyze 
    the evolution of chatbot integration in education.
    """
    print("Initiating data collection from arXiv...")

    #Search query focused on Chatbots AND Education
    url = 'https://arxiv.org/search/cs?query="chatbot"+AND+"education"&searchtype=all&abstracts=show&order=-announced_date_first&size=25'
    
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64)'}

    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
    except Exception as e:
        print(f"Connection error: {e}")
        return []

    soup = BeautifulSoup(response.text, 'html.parser')
    papers_data = []

    #Target specific HTML structures for academic metadata
    results = soup.find_all('li', class_='arxiv-result')

    for result in results:
        try:
            title = result.find('p', class_='title').text.strip()
            authors = result.find('p', class_='authors').text.replace('Authors:', '').strip()
            
            #Cleaning the abstract text
            abstract_span = result.find('span', class_='abstract-full')
            if abstract_span.find('a'):
                abstract_span.find('a').decompose()
            abstract = abstract_span.text.strip()

            papers_data.append({
                'title': title,
                'authors': authors,
                'abstract': abstract
            })
        except AttributeError:
            continue

    print(f"Task completed: {len(papers_data)} papers indexed.")
    return papers_data

#Execute pipeline
data = scrape_educational_research()

#Data processing and analyysis
df = pd.DataFrame(data)
if not df.empty:
    print("\nProcessing text metrics (Length and Word Count)...")
    df['abstract_length'] = df['abstract'].apply(len)
    df['word_count'] = df['abstract'].apply(lambda x: len(x.split()))

    #Export to JSON for downstream analysis
    output_file = 'chatbot_research_data.json'
    df.to_json(output_file, orient='records', indent=4)
    print(f"Structured dataset exported to: {output_file}")

    #Preview of the collected data
    print(df[['title', 'word_count', 'abstract_length']].head())
